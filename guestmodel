#!/usr/bin/env python3

import time
import os
import sys
import argparse

import collections
import math
import numpy
import math
from scipy.stats import norm
from scipy.stats import logistic
from scipy.optimize import curve_fit

import util

class Program:
	_options = None

	def __init__(self):
		parser = argparse.ArgumentParser(
			description="Guest model.")
		parser.add_argument('-d', '--stats-dir', type=str,
			default='/host', required=True,
			help='directory of statistics provided by the host')
		self._options = parser.parse_args()
		#print(self._options)

	def main(self):
		try:
			if not os.path.isdir(self._options.stats_dir): raise Exception('parameter --stats-dir="{}" not found a directory'.format(self._args.stats_dir))

			host_stats = util.WatchLog('{}/stats-1'.format(self._options.stats_dir), 'json')

			model5m   = ModelInterface('model-5m',  300)

			while True:
				time.sleep(1)

				lines = host_stats.read()
				for l in lines:
					s = GuestStats(l)
					model5m.feed(s)

				model5m.printResults()

		# Exit conditions:
		except KeyboardInterrupt:
			return 0
		'''except Exception as e:
			sys.stderr.write('error: {}\n'.format(str(e)))
			return 1  #'''
		return 0

class ModelInterface:
	_range1    = numpy.array([float(i)/100. for i in range(0, 101, 5)])
	_range100  = [i for i in range(0,101,5)]
	# Statistics origin
	_prefix            = None
	_sample_limit      = 0
	# Hardware information
	_host_cpus         = None
	# Time Serie Values:
	_stats              = None
	_other_demand_count = None
	_guest_model        = None

	def __init__(self, prefix, sample_limit):
		assert sample_limit >= 0
		self._prefix       = prefix
		self._sample_limit = sample_limit
		#self._other_demand = MarkovChain(11, sample_limit=sample_limit) # 0-10 states

		self._stats = Llist(limit=sample_limit)
		self._other_demand_count = numpy.array([ 0 for i in range(0,len(self._range100)) ])

	def feed(self, stats):
		if self._host_cpus == None:
			self._host_cpus = stats.host_cpus

		deleted_stats = self._stats.append(stats)
		self.addHist(stats, deleted_stats)

		gm = self._guest_model
		if gm is None or (gm._cpus, gm._vcpus, gm._guest_vcpus) != (stats.host_cpus, stats.total_vcpus, stats.guest_vcpus):
			print('Creating new guest model: {}'.format((stats.host_cpus, stats.total_vcpus, stats.guest_vcpus)))
			self._guest_model = GuestModel(stats.host_cpus, stats.total_vcpus, stats.guest_vcpus)

	def printResults(self):
		last_stats = self._stats[-1]
		print()
		print( 'Guest Usage          : {:5.1f}%     Guest Demand      : {:5.1f}%'.format(last_stats.guest_usage * 100., last_stats.guest_demand * 100. ))
		print( 'Total VCPUs:         : {:>2}         Other Demand      : {:5.1f}%'.format(last_stats.total_vcpus, 100. * last_stats.other_demand/last_stats.other_vcpus ))
		print( 'Scale (%) ---------- : {}'.format(' '.join([ '{:>3}'.format(i) for i in self._range100 ])) )
		print( 'Other Demand Hist.   : {}'.format(' '.join([ '{:3.0f}'.format(i) for i in self.histogram100 ])) )
		print( 'Potential VCPU Time  : {}'.format(' '.join([ '{:3.0f}'.format(i) for i in self.potential100 ])) )

	@property
	def histogram1(self):
		return self._other_demand_count / len(self._stats)
	@property
	def histogram100(self):
		return 100. * self.histogram1

	_cache_potential_matrix = None
	@property
	def potential1(self):
		if self._cache_potential_matrix is None:
			gm = self._guest_model
			self._cache_potential_matrix = pm = []

			X = self._range1 * (gm._vcpus - gm._guest_vcpus)
			for i in X:
				f, params = gm.potentialSF(i)
				pm.append(util.minmax(f(self._range1, *params),0., 1.))

			self._cache_potential_matrix = pm = numpy.array(pm)
		else:
			pm = self._cache_potential_matrix

		hist = self.histogram1
		return pm @ hist.T
	@property
	def potential100(self):
		return 100 * self.potential1

	def addHist(self, stats, deleted_stats):
		if deleted_stats is not None:
			self._other_demand_count[self.getOtherDemandIdx(deleted_stats)] -= 1
		self._other_demand_count[self.getOtherDemandIdx(stats)] += 1

	def convertRangeIdx1(self, value):
		return int(round(value/(self._range1[1]-self._range1[0]), 0))
	def getOtherDemandIdx(self, stats):
		return self.convertRangeIdx1(stats.other_demand/stats.other_vcpus)

class GuestModel:
	_cpus         = None # physical CPUs
	_vcpus        = None # total VCPUs
	_guest_vcpus  = None

	def __init__(self, cpus, vcpus, guest_vcpus):
		assert cpus > 0
		assert vcpus >= guest_vcpus
		self._cpus         = cpus
		self._vcpus        = vcpus
		self._guest_vcpus  = guest_vcpus

	_cache_minima = None
	@property
	def minima(self):
		if self._cache_minima is None:
			if self._cpus >= self._vcpus: return (1., 1., 1.)
			lrM2c, lrM2i = numpy.array([-0.13706281,  0.03796571,  1.92678371]), -0.18650532291443023

			pr = float(self._vcpus % self._cpus) / self._cpus
			min1 = 1. / math.ceil(self._vcpus / self._cpus)
			min2 = util.minmax(
				lrM2c @ [self._cpus, self._vcpus, float(self._cpus)/self._vcpus] + lrM2i,
				min1, float(self._guest_vcpus))
			self._cache_minima = (pr, min1, min2)
		return self._cache_minima

	def predict1(self, other_demand):
		if other_demand < 0: other_demand = 0.
		ret = round(float(self._cpus) / float(other_demand + self._guest_vcpus), 3)
		if ret > self._guest_vcpus:
			ret = float(self._guest_vcpus)
		return ret

	def getMinMaxDemand(self, coef, intercept):
		other_vcpus = self._vcpus - self._guest_vcpus
		assert other_vcpus >= 0

		maxdemand = float(other_vcpus)
		#linear model (cpus, vcpus/cpus) -> V'i - D'i
		mindemand = other_vcpus - (coef @ [self._cpus, float(self._vcpus)/self._cpus] + intercept)
		return (util.minmax(mindemand, 0., maxdemand), maxdemand)

	_cache_upperMinMaxDemand = None
	@property
	def upperMinMaxDemand(self):
		if self._cache_upperMinMaxDemand is None:
			#linear model (cpus, vcpus/cpus) -> V'i - D'i
			coef, intercept = numpy.array([1.79802902, 3.06745787]), -9.581261143965314
			self._cache_upperMinMaxDemand = self.getMinMaxDemand(coef, intercept)
		return self._cache_upperMinMaxDemand

	_cache_middleMinMaxDemand = None
	@property
	def middleMinMaxDemand(self):
		if self._cache_middleMinMaxDemand is None:
			#linear model (cpus, vcpus/cpus) -> V'i - D'i
			coef, intercept = numpy.array([1.65132364, 3.3874511 ]), -9.242054264663107
			self._cache_middleMinMaxDemand = self.getMinMaxDemand(coef, intercept)
		return self._cache_middleMinMaxDemand

	_cache_lowerMinMaxDemand = None
	@property
	def lowerMinMaxDemand(self):
		if self._cache_lowerMinMaxDemand is None:
			#linear model (cpus, vcpus/cpus) -> V'i - D'i
			coef, intercept = numpy.array([1.68083004, 3.6729249 ]), -9.239624505928855
			self._cache_lowerMinMaxDemand = self.getMinMaxDemand(coef, intercept)
		return self._cache_lowerMinMaxDemand

	_cache_lowerMinMaxT = None
	@property
	def lowerMinMaxT(self):
		if self._cache_lowerMinMaxT is None:
			_, minimum, _ = self.minima
			maximum = .99 * float(self._guest_vcpus)
			self._cache_lowerMinMaxT = (util.minmax(minimum, 0., 1.), maximum)
		return self._cache_lowerMinMaxT

	_cache_predictLower_points = None
	_cache_predictLower = None
	def predictLower(self, other_demand):
		minimum, maximum = self.lowerMinMaxT

		other_vcpus = self._vcpus - self._guest_vcpus
		if other_demand < 0: other_demand = 0.
		if other_vcpus <= 0: return maximum

		f = self.sigmoid

		if self._cache_predictLower is None:
			def fLinear(x, a, b): # linear
				return a*x + b

			lrB_coef, lrB_inter = numpy.array([ 0.13784643, -0.04689495,  0.9865885 , -0.03939464]), 0.28566658562732805
			lrT_coef, lrT_inter = numpy.array([ 0.28538262,  0.0057059 , -0.07499791,  0.0057059 ]), -0.28653033347650414

			mindemand, maxdemand = self.lowerMinMaxDemand

			skBx, skBy = maxdemand * (lrB_coef @ [self._cpus, self._vcpus, maximum-minimum, maxdemand-mindemand] + lrB_inter), minimum
			if skBx > (maxdemand * .97): skBx = maxdemand * .97
			skTx, skTy = mindemand + (lrT_coef @ [self._cpus, self._vcpus, mindemand, maxdemand] + lrT_inter), maximum
			if skTx < (mindemand * 1.03): skTx = mindemand * 1.03
			if skTx > (skBx * .97): skTx = skBx * .97
			#print('skTx, skTy: ', (skTx, skTy))
			#print('skBx, skBy: ', (skBx, skBy))

			popt_sk, _ = curve_fit(fLinear, [skTx, skBx], [skTy, skBy])
			fx = lambda x: skTx + x * (skBx - skTx)
			midRatios = numpy.linspace(.40, .50, 5)
			midX = [ fx(i) for i in midRatios ]
			midY = [ fLinear(i, *popt_sk) for i in midX ]

			fitX = [mindemand] + midX + [maxdemand]
			fitY = [maximum]   + midY + [minimum]
			self._cache_predictLower_points = ([skTx, skBx] + fitX, [skTy, skBy] + fitY)
			#print('fitX: ', fitX)
			#print('fitY: ', fitY)
			method = None
			if self._cpus == 3: method = 'dogbox'
			popt, _ = curve_fit(f, fitX, fitY, method=method)
			self._cache_predictLower = (popt, mindemand, maxdemand, minimum)
			#print('popt: ', popt)
		else:
			popt, mindemand, maxdemand, minimum = self._cache_predictLower

		if other_demand <= mindemand: return maximum
		if maxdemand <= 0 or mindemand >= maxdemand: return maximum

		return util.minmax(f(other_demand, *popt), 0., 1.)

	_cache_upperMinMaxT = None
	@property
	def upperMinMaxT(self):
		if self._cache_upperMinMaxT is None:
			_, _, minimum = self.minima
			maximum = float(self._guest_vcpus)
			self._cache_upperMinMaxT = (util.minmax(minimum, 0., maximum), maximum)
		return self._cache_upperMinMaxT

	_cache_predictUpper_points = None
	_cache_predictUpper = None
	def predictUpper(self, other_demand):
		minimum, maximum = self.upperMinMaxT
		mindemand, maxdemand = self.upperMinMaxDemand
		def f(x, y0, c, k):
			return c / (1 + numpy.exp(-k*(x-maxdemand))) + y0

		other_vcpus = self._vcpus - self._guest_vcpus
		if minimum == maximum or mindemand == maxdemand: return maximum
		if other_demand < 0: other_demand = 0.
		if other_vcpus <= 0: return maximum

		if self._cache_predictUpper is None:
			def fLinear(x, a, b):
				return a*x + b

			# linear regression: [mindemand, maxdemand, minimum] -> D'i
			sk_coef, sk_inter = numpy.array([ 0.62330553,  0.25020868, -1.64968515]), 1.5897770409774998
			skx = sk_coef @ [mindemand, maxdemand, minimum] + sk_inter
			sky = maximum
			if skx > maxdemand or skx < mindemand: #sanity check
				skx = (maxdemand + mindemand)/2.
			#print('skx, sky: ', skx, sky)

			midP, _ = curve_fit(fLinear, [skx, maxdemand], [sky, minimum])
			midX = numpy.linspace(maxdemand - .02*(maxdemand-mindemand), maxdemand, 7)
			midY = fLinear(midX, *midP)

			fitX = [mindemand] + list(midX) + [maxdemand]
			fitY = [maximum]   + list(midY) + [minimum]
			self._cache_predictUpper_points = ([skx] + fitX, [sky] + fitY)
			#print('fitX: ', fitX)
			#print('fitY: ', fitY)
			method = None
			#if self._cpus == 3: method = 'dogbox'
			popt, _ = curve_fit(f, fitX, fitY, method=method)
			self._cache_predictUpper = popt
			#print('popt: ', popt)
		else:
			popt = self._cache_predictUpper

		if other_demand <= mindemand: return maximum
		if maxdemand <= 0 or mindemand >= maxdemand: return maximum

		return util.minmax(f(other_demand, *popt), minimum, maximum)

	@staticmethod
	def sigmoid(x, x0, y0, c, k): #sigmoid function
		return c / (1 + numpy.exp(-k*(x-x0))) + y0
	@staticmethod
	def linear(x, a, b): # linear function
		return a*x + b

	_cache_potentialSF = dict()
	_cache_potentialSF_fitX = numpy.linspace(-1.,2.,50)
	def potentialSF(self, other_demand):
		od_idx = int(other_demand * 10)
		other_demand = util.minmax(round(other_demand, 1), 0., float(self._vcpus - self._guest_vcpus))

		if self._cache_potentialSF.get(od_idx) is None:
			md_lower, _   = self.lowerMinMaxDemand
			md_middle, _  = self.middleMinMaxDemand
			md_upper, _   = self.upperMinMaxDemand
			_, maxima     = self.upperMinMaxT

			x_upper = self.predictUpper(other_demand)
			x_lower = self.predictLower(other_demand)

			if other_demand <= md_lower:
				params = []
				f = lambda x: x**0
			else:
				f = self.sigmoid
				min = x_lower
				if other_demand <= md_middle:
					max = x_lower + (maxima-x_lower)*2.
				elif other_demand <= md_upper:
					midP, _ = curve_fit(self.linear, [md_middle, md_upper], [maxima, (maxima + x_lower)/2.])
					max = x_lower + 2. * (self.linear(other_demand, *midP) - x_lower)
				else:
					max = x_upper

				fitX = self._cache_potentialSF_fitX
				fitY = [ 1. if x <= min else 0. if x >= max else 1. - (x - min)/(max - min) for x in fitX]
				params, _ = curve_fit(f, fitX, fitY)

			self._cache_potentialSF[od_idx] = (f, params)

		return self._cache_potentialSF[od_idx]

class GuestStats:
	time         = None
	host_cpulist = None
	host_cpus    = None
	total_vcpus  = None
	total_usage  = None
	total_steal  = None
	total_demand = None
	guest_vcpus  = None
	guest_usage  = None
	guest_steal  = None
	guest_demand = None
	def __init__(self, line):
		self.time         = int(line['time'])
		map = line['vm']['vcpu'][0]['map']
		self.host_cpulist = []
		for i in range(0,len(map)):
			if map[i] == True: self.host_cpulist.append(i)
		self.host_cpus    = len(self.host_cpulist)
		self.total_vcpus  = line['vm_totals']['vcpu_count']
		self.total_usage  = line['vm_totals']['usage'] / 100.
		self.total_steal  = line['vm_totals']['steal'] / 100.
		self.total_demand = util.max(self.total_usage + self.total_steal, self.total_vcpus)
		self.guest_vcpus  = line['vm']['vcpu_count']
		self.guest_usage  = sum([ i['usage'] for i in line['vm']['vcpu'] ]) / 100.
		self.guest_steal  = sum([ i['steal'] for i in line['vm']['vcpu'] ]) / 100.
		self.guest_demand = util.max(self.guest_usage + self.guest_steal, self.guest_vcpus)
	@property
	def other_vcpus(self):  return self.total_vcpus - self.guest_vcpus
	@property
	def other_demand(self): return util.minmax(float(self.total_demand - self.guest_demand), 0., float(self.other_vcpus))

#############################################################################
# GENERIC STRICTURES
#############################################################################

class MarkovChain:
	_size          = None # Matrix size
	_names         = None # State names
	_counts        = None # Line sum
	_matrix        = None # Transition matrix
	_sample_limit  = 0
	_sample_size   = 0
	_sample        = []
	_last_state    = None

	def __init__(self, size, names=None, sample_limit=0):
		assert isinstance(size, int) and size > 1
		assert names == None or (isinstance(names, list) and len(names) == size)
		assert isinstance(sample_limit, int) and sample_limit >= 0
		self._size = size
		self._names = names
		self._sample_limit = sample_limit
		self._counts = [ 0 for i in range(0,size) ]
		self._matrix = numpy.array( [ [ 0 for j in range(0,size) ] for i in range(0,size) ] )

	def getMatrix(self):
		ret = numpy.array( [ [ 0. for j in range(0,self._size) ] for i in range(0,self._size) ] )
		for i in range(0,self._size):
			ret[i] = self._matrix[i]/self._counts[i] if self._counts[i] > 0 else [1./self._size for j in range(0,self._size)]
		return ret

	def predict(self, states, times=1):
		assert len(states) == self._size
		assert times > 0
		m = self.getMatrix()
		#print(m)
		ret = states.copy()
		for i in range(0,times):
			ret = ret @ m
		return ret

	def predictNext(self):
		if self._last_state != None:
			states = numpy.array([ (1 if i == self._last_state else 0) for i in range(0,self._size) ])
			return self.predict(states)
		return None

	def histogram(self):
		ret = numpy.array(self._counts, float)
		return ret / self._sample_size

	def increment(self, states):
		if isinstance(states, int):
			state_from = self._last_state
			state_to = states
		elif isinstance(states, tuple):
			state_from, state_to = states
		else: raise Exception('wrong parameter states')

		assert state_from == None or (state_from >=0 and state_from < self._size)
		assert state_to >= 0 and state_to < self._size

		if state_from != None:
			self._counts[state_from] += 1
			self._matrix[state_from][state_to] += 1
			self._sample_size += 1
			self._sample.append((state_from, state_to))

		self._last_state = state_to

		if self._sample_limit > 0:
			while self._sample_size > self._sample_limit:
				self.decrement()

	def decrement(self):
		if self._sample_size > 0:
			state_from, state_to = self._sample.pop(0)
			self._sample_size -= 1

			if self._counts[state_from] <= 0 or self._matrix[state_from][state_to] <= 0:
				self.debugData()
				raise Exception('decrement error in the class MarkovChain: self._counts[{f}] = {c} or self._matrix[{f}][{t}] = {m}'.format(f=state_from, t=state_to, c=self._counts[state_from], m=self._matrix[state_from][state_to]))

			self._counts[state_from] -= 1
			self._matrix[state_from][state_to] -= 1

	def size(self):
		return self._size

	def debugData(self):
		print('Sample Size       : {}'.format(self._sample_size))
		print('Counts            : {}'.format(self._counts))
		print('Transition Matrix : \n{}'.format(self._matrix))

class Llist(list):
	_limit = 0

	def __init__(self, limit=0):
		assert isinstance(limit, int) and limit >= 0
		self._limit = limit
		list.__init__(self)

	def append(self, item):
		list.append(self, item)
		if self._limit > 0 and len(self) > self._limit:
			return self.pop(0)
		return None

if __name__ == '__main__':
	exit(Program().main())
